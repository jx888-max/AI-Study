# 大模型相关干货

## 一，论文解读
### 1，康奈尔大学运营的免费分发服务和开放获取档案库，评估论文质量的责任完全在于读者。（https://arxiv.org/）
### 2，ACM DL的对应机构，是计算机科学、电气工程和电子学领域的研究数据库。(https://ieeexplore.ieee.org/)
### 3，收录了所有ACM出版的期刊文章、会议论文集、技术杂志和书籍。(https://dl.acm.org/)
### 4，谷歌学术是一个可免费访问的网络搜索引擎。（https://scholar.google.com/）
### 5，由艾伦人工智能研究所（Allen Institute for AI）开发的Semantic Scholar，是一个采用AI技术增强的学术搜索引擎。(https://www.semanticscholar.org/) 
### 6，一个免费、开放的机器学习论文、代码、数据集和评估排行榜的资源库。(https://paperswithcode.com/) 
### 7，由清华大学计算机系研发的AMiner是一个基于人工智能的对话式文献知识库。（https://www.aminer.cn/）



## 二，手撕代码
### 1，特斯拉前AI总监：https://github.com/karpathy
### 2，从头开始逐步在 PyTorch 中实现类似 ChatGPT 的 LLM。https://github.com/rasbt/LLMs-from-scratch
### 3，深度学习。https://github.com/awesomelistsio/awesome-deep-learning
### 4，一些AI公共GitHub代码库。https://www.oneclickitsolution.com/centerofexcellence/aiml/top-ai-github-repositories-2025
### 5，一份优秀的Python机器学习库排名列表。https://github.com/lukasmasuch/best-of-ml-python
### 6，从零开始构建神经网络。https://github.com/chizkidd/Karpathy-Neural-Networks-Zero-to-Hero
### 7，专门研究大型语言模型（LLM）、深度学习的老师。https://github.com/rasbt    https://huggingface.co/rasbt
### 8，Meta AI。https://github.com/facebookresearch
### 9，Reddit的LocalLLaMA。https://www.reddit.com/r/LocalLLaMA/comments/1npzstw/a_step_by_step_guide_on_how_to_build_a_llm_from/
### 10，Hugging Face课程。https://github.com/huggingface/course
### 11，用于高效 RAG 研究的 Python 工具包。https://github.com/RUC-NLPIR/FlashRAG



# 三，博客参考
### 1，https://linux.do/
### 2，https://juejin.cn/
### 3，曾在OpenAI工作的Lilian Weng以其极其详尽、深入的博文而闻名。https://lilianweng.github.io/
### 4，这是一个发布在Medium上的大型社区博客。https://towardsdatascience.com/
### 5，Google DeepMind (https://deepmind.google/blog/)
### 6，Meta AI (https://ai.meta.com/blog/)   
### 7，Microsoft Research Blog (https://www.microsoft.com/en-us/research/blog/)  
### 8，Amazon Science (https://www.amazon.science/blog)
### 9，Apple Machine Learning Research (https://machinelearning.apple.com/) 
### 10，NVIDIA Technical Blog (https://blogs.nvidia.com/)
### 11，苏剑林，一位科技博主。https://spaces.ac.cn/category/Mathematics



# 四，开源模型
### 1，DeepSeek-R1：通过强化学习激励推理能力。https://github.com/deepseek-ai/DeepSeek-R1
### 2，从零开始构建 DeepSeek R1。https://github.com/FareedKhan-dev/train-deepseek-r1
### 3，思想学。https://arxiv.org/abs/2504.07128   可解释情感分析。https://arxiv.org/abs/2503.11655
### 4，DeepSeek-V3.1。https://huggingface.co/deepseek-ai/DeepSeek-V3.1
### 5，DeepSeek-V3.2。https://skywork.ai/blog/deepseek-v3-2-exp-hugging-face-accessible-efficient-and-ready-to-experiment/   https://github.com/deepseek-ai/DeepSeek-V3.2-Exp
### 6，GPT-oss。https://github.com/openai/gpt-oss  反常缩放。https://arxiv.org/pdf/2508.12461
### 7，GLM4.5。https://github.com/zai-org/GLM-4.5   GLM4.6。https://huggingface.co/zai-org/GLM-4.6
### 8，Minimax-M2。https://github.com/MiniMax-AI/MiniMax-M2
### 9，Qwen3-VL。https://github.com/QwenLM/Qwen3-VL
### 10，Qwen3-Coder。https://github.com/QwenLM/Qwen3-Coder
### 11，Qwen3-Omni。https://github.com/QwenLM/Qwen3-Omni
### 12，Google Gemma 模型的官方 PyTorch 实现。https://github.com/google/gemma_pytorch
### 13，Gemma 开放式 LLM 库。https://github.com/google-deepmind/gemma
### 14，Google Gemma 开放模型的指南和示例集合。https://github.com/google-gemini/gemma-cookbook